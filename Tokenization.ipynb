{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad79addb",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Tokenization is at the hearf of LLMs\n",
    "\n",
    "<small> Simple string processing can be difficult due to tokenization for LLM </small>\n",
    "\n",
    "<small> Sometimes LLMs are bad at artithmetic due to tokenization </small>\n",
    "\n",
    "<small> Earlier versions of gpt had issues with Python due to tokenization </small>\n",
    "\n",
    "<small> LLMs do worse for non english languages due to tokenization </small>\n",
    "\n",
    "<small> Using YAML over json due to tokenization </small>\n",
    "\n",
    "<small> tiktokenizer.vercel.app is good for visualizing tokenization </small>\n",
    "\n",
    "<small>So like even for the same concept \"egg\" can be very different tokens and ids. The model has to somehow learn that these are the same concept and group them in the nn properly. </small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246edca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
